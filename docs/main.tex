% document class

\documentclass[12pt]{article}


% use packages

\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage[ddmmyyyy]{datetime}
\usepackage{color}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{
colorlinks=true,
linkcolor=[RGB]{0,51,102},
citecolor=[RGB]{0,51,102},
urlcolor=[RGB]{74, 133, 150}
}
\usepackage[medium]{titlesec}
\usepackage{geometry}
\usepackage{xurl}
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{etoolbox}
\makeatletter
\patchcmd{\NAT@citex}
  {\@citea\NAT@hyper@{%
     \NAT@nmfmt{\NAT@nm}%
     \hyper@natlinkbreak{\NAT@aysep\NAT@spacechar}{\@citeb\@extra@b@citeb}%
     \NAT@date}}
  {\@citea\NAT@nmfmt{\NAT@nm}%
   \NAT@aysep\NAT@spacechar\NAT@hyper@{\NAT@date}}{}{}
\patchcmd{\NAT@citex}
  {\@citea\NAT@hyper@{%
     \NAT@nmfmt{\NAT@nm}%
     \hyper@natlinkbreak{\NAT@spacechar\NAT@@open\if*#1*\else#1\NAT@spacechar\fi}%
       {\@citeb\@extra@b@citeb}%
     \NAT@date}}
  {\@citea\NAT@nmfmt{\NAT@nm}%
   \NAT@spacechar\NAT@@open\if*#1*\else#1\NAT@spacechar\fi\NAT@hyper@{\NAT@date}}
  {}{}
 \makeatother
 % reduce space between references
\setlength{\bibsep}{0pt plus 0.3ex}
\usepackage{filecontents}[overwrite]

% adjust settings

\newgeometry{
lmargin=2.5cm,
rmargin=2.5cm,
tmargin=2.5cm,
bmargin=2.5cm
}


% configure title
\title{\vspace{-2cm} plasso \\ Introduction}
\author{Michael Knaus \\ Stefan Glaisner}
\date{\today}
\date{\today}


 % document
 
\begin{document}


\begin{filecontents}{ref.bib}
@article{glmnet,
   author = {Jerome Friedman and Trevor Hastie and Robert Tibshirani},
   title = {Regularization Paths for Generalized Linear Models via Coordinate Descent},
   journal = {Journal of Statistical Software},
   volume = {33},
   number = {1},
   year = {2010},
   keywords = {},
   abstract = {We develop fast algorithms for estimation of generalized linear models with convex penalties. The models include linear regression, two-class logistic regression, and multi- nomial regression problems while the penalties include ℓ1 (the lasso), ℓ2 (ridge regression) and mixtures of the two (the elastic net). The algorithms use cyclical coordinate descent, computed along a regularization path. The methods can handle large problems and can also deal efficiently with sparse features. In comparative timings we find that the new algorithms are considerably faster than competing methods.},
   issn = {1548-7660},
   pages = {1--22},
   doi = {10.18637/jss.v033.i01},
   url = {https://www.jstatsoft.org/v033/i01}
}

@article{knaus,
    author = {Knaus, Michael C},
    title = "{Double machine learning-based programme evaluation under unconfoundedness}",
    journal = {The Econometrics Journal},
    volume = {25},
    number = {3},
    pages = {602-627},
    year = {2022},
    month = {06},
    abstract = "{This paper reviews, applies, and extends recently proposed methods based on double machine learning (DML) with a focus on programme evaluation under unconfoundedness. DML-based methods leverage flexible prediction models to adjust for confounding variables in the estimation of (a) standard average effects, (b) different forms of heterogeneous effects, and (c) optimal treatment assignment rules. An evaluation of multiple programmes of the Swiss Active Labour Market Policy illustrates how DML-based methods enable a comprehensive programme evaluation. Motivated by extreme individualised treatment effect estimates of the DR-learner, we propose the normalised DR-learner (NDR-learner) to address this issue. The NDR-learner acknowledges that individualised effect estimates can be stabilised by an individualised normalisation of inverse probability weights.}",
    issn = {1368-4221},
    doi = {10.1093/ectj/utac015},
    url = {https://doi.org/10.1093/ectj/utac015},
    eprint = {https://academic.oup.com/ectj/article-pdf/25/3/602/45842097/utac015.pdf},
}

@Manual{plasso,
  title={plasso: Cross-validated Post-Lasso},
  author={Michael Knaus and Stefan Glaisner},
  year={2023},
  note={R package version 0.1.1},
  url={https://CRAN.R-project.org/package=plasso}
}
\end{filecontents}

\maketitle

This document is meant as a short overview over the \emph{plasso} package by \citet{plasso}.

\section{General idea}

Built on top of the \emph{glmnet} library by \citet{glmnet}, the \emph{plasso} package follows \citet{knaus} and comes up with two main functions that both estimate least squares Lasso and Post-Lasso models. The \emph{plasso()} function adds coefficient paths for a Post-Lasso model to the \emph{glmnet()} output of a standard Lasso model using the same values for the penalty term lambda.\\
On top of that, \emph{cv.plasso()} cross-validates all Lasso and Post-Lasso models. The function output includes mean squared errors (MSEs) for all models, and, the most optimal lambda hyperparameter value (according to minimum MSE or alternative definitions such as the one-standard-error-rule).\\

Both functions come with several S3 methods attached. \emph{cv.plasso()} allows for a cross-validation focused \emph{summary} output including the lambda value and the names of the active set at the minimum. Both functions incorporate a \emph{predict} method that can be used for prediction of both fitted values and coefficients - either across the whole lambda sequence or for a specified lambda value. The coefficients can also be obtained by using the \emph{coef} method associated to both functions.\\
Interesting insights into the models can also be inferred from the \emph{plot} method. For both functions, the \emph{plot} method is quite similar to its respective \emph{glmnet} counterpart. \emph{plasso()} visualises the coefficient paths - either for the Lasso or Post-Lasso model depending on the specification of option \emph{lasso} (default is \emph{FALSE}). \emph{cv.plasso()}, on the other hand, unifies both models by representing the MSEs and number of active coefficients along the whole sequence of lambda values.\\

For an even more comprehensive overview including exemplary code, have a look at the package's \href{https://cran.r-project.org/web/packages/plasso/vignettes/plasso.html}{vignette.}

\section{Technical implementation}

Heretofore, the code is entirely written in R. The first step in both \emph{cv.plasso()} and \emph{plasso()} is a \emph{glmnet()} call for the estimation of the Lasso model and the extraction of the chosen sequence of lambda values. The code is written such as that the Post-Lasso model is newly estimated every time the active set changes. By doing so the computational burden is reduced as we do not have to estimate the Post-Lasso model for the whole lambda sequence.

\section{Contact}

For reporting a bug, simply \href{https://github.com/stefan-1997/NuisanceParameters/issues/new}{open an issue} on GitHub. For personal contact, you can write an email to michael.knaus@uni-tuebingen.de.

\bibliography{ref}

\end{document}